阶段 1：基础资料准备

统计各日 CSV 中文本/图片/图文帖子数量，确定 modality ∈ {text_only, image_only, text_image} 标记方案。
清理并补充图像种子集（prototypes/…），同时从文本中抽样构建手工标注小集合（情绪、主题、风险提示等）。
梳理现有脚本输出，确认所需依赖安装与运行环境（Mac / 服务器）配置。
阶段 2：主类与细分类融合

完善 classify_media.py：
对含图帖子调用图像分类（含原型增强），输出主类与细分类字段。
新增文本处理模块（分词、情绪/主题识别）；缺图时仅跑文本路径。
每条记录统一输出 modality、是否使用文本/图片、图文标签与置信度。
引入 --aggregation post 模式，汇总同一 post_id 的多图结果，并保留 --media-level image 调试选项。
阶段 3：细粒度标注逻辑

technical_chart：识别趋势（上涨/下跌/震荡/不确定），必要时结合OCR读取价格区间。
news_screenshot：OCR 抽取标题与核心段落，做积极/消极/中性判定。
gold_bullion：区分金条/金币/首饰/包装等类型，可先用种子集+CLIP或轻量模型实现。
meme：通过文本 + 图像情绪判断正负面，输出情绪标签。
文本专属补充：对纯文本帖子做相同的情绪/主题分析，确保输出结构一致。
阶段 4：结果汇总与验证

生成新的汇总 CSV（按 post_id），包含日期、作者、文本情绪、图像主类及细分类、modality、置信度、原始文本摘要等。
保留逐图中间结果文件以便调试。
设定质量检验流程：抽样人工复核、计算准确率/F1，并根据问题回滚或调整原型/阈值。
阶段 5：时间序列特征工程接入

从汇总 CSV 自动提取每日统计特征：各类图片数量、情绪比例、技术图上涨占比等。
将这些特征接入现有 LSTM/预测管线（1GoldPred 项目）并评估对预测性能的提升。
迭代优化，记录实验设置与效果，便于后续上服务器批量运行。
阶段 6：部署与自动化

配置服务器运行脚本：准备依赖环境、同步原型集与配置。
编写命令或脚本实现批量日期处理、日志记录和错误告警。
根据需要拓展到其他关键词或项目（如比特币、景区预测），复用流程。# WeiboData
# WeiboData
